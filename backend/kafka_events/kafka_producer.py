"""
Kafka Producer –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–±—ã—Ç–∏–π
"""
import json
import logging
import uuid
from typing import Dict, Any, Optional
from datetime import datetime
from kafka import KafkaProducer
from kafka.errors import KafkaError, KafkaTimeoutError
from .kafka_config import kafka_config
from .kafka_events import BaseEvent

logger = logging.getLogger(__name__)

class KafkaEventProducer:
    """Producer –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–±—ã—Ç–∏–π –≤ Kafka"""
    
    def __init__(self):
        self.producer = None
        self._initialize_producer()
    
    def _initialize_producer(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Kafka producer"""
        if not kafka_config.enabled:
            logger.info("Kafka –æ—Ç–∫–ª—é—á–µ–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
            return
            
        try:
            producer_config = {
                'bootstrap_servers': kafka_config.bootstrap_servers.split(','),
                'acks': kafka_config.producer_acks,
                'retries': kafka_config.producer_retries,
                'batch_size': kafka_config.producer_batch_size,
                'linger_ms': kafka_config.producer_linger_ms,
                'compression_type': kafka_config.producer_compression_type,
                'value_serializer': lambda v: json.dumps(v, default=str).encode('utf-8'),
                'key_serializer': lambda k: str(k).encode('utf-8') if k else None,
                'request_timeout_ms': 30000,
                'metadata_max_age_ms': 300000,
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if kafka_config.security_protocol != "PLAINTEXT":
                producer_config.update({
                    'security_protocol': kafka_config.security_protocol,
                    'sasl_mechanism': kafka_config.sasl_mechanism,
                    'sasl_plain_username': kafka_config.sasl_username,
                    'sasl_plain_password': kafka_config.sasl_password,
                })
            
            self.producer = KafkaProducer(**producer_config)
            logger.info("‚úÖ Kafka Producer –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Kafka Producer: {e}")
            raise
    
    def publish_event(
        self, 
        topic: str, 
        event: BaseEvent, 
        key: Optional[str] = None,
        partition: Optional[int] = None
    ) -> bool:
        """
        –ü—É–±–ª–∏–∫–∞—Ü–∏—è —Å–æ–±—ã—Ç–∏—è –≤ Kafka
        
        Args:
            topic: –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–ø–∏–∫–∞
            event: –û–±—ä–µ–∫—Ç —Å–æ–±—ã—Ç–∏—è
            key: –ö–ª—é—á –¥–ª—è –ø–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            partition: –ö–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è –ø–∞—Ä—Ç–∏—Ü–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        
        Returns:
            bool: True –µ—Å–ª–∏ —Å–æ–±—ã—Ç–∏–µ —É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ
        """
        try:
            if not kafka_config.enabled:
                logger.info(f"Kafka –æ—Ç–∫–ª—é—á–µ–Ω, —Å–æ–±—ã—Ç–∏–µ {event.event_type} –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ")
                return True
                
            if not self.producer:
                logger.error("Kafka producer –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
                return False
            if not event.event_id:
                event.event_id = str(uuid.uuid4())
            
            # –î–æ–±–∞–≤–ª—è–µ–º correlation_id –µ—Å–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω
            if not event.correlation_id:
                event.correlation_id = str(uuid.uuid4())
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏
            event_data = event.dict()
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–ª—é—á –¥–ª—è –ø–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
            partition_key = key or self._get_partition_key(event)
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–±—ã—Ç–∏–µ
            future = self.producer.send(
                topic=topic,
                value=event_data,
                key=partition_key,
                partition=partition
            )
            
            # –ñ–¥–µ–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
            record_metadata = future.get(timeout=10)
            
            logger.info(
                f"‚úÖ –°–æ–±—ã—Ç–∏–µ {event.event_type} –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ —Ç–æ–ø–∏–∫ {topic}, "
                f"–ø–∞—Ä—Ç–∏—Ü–∏—è {record_metadata.partition}, "
                f"offset {record_metadata.offset}"
            )
            
            return True
            
        except KafkaTimeoutError:
            logger.error(f"‚è∞ –¢–∞–π–º–∞—É—Ç –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–±—ã—Ç–∏—è {event.event_type} –≤ —Ç–æ–ø–∏–∫ {topic}")
            return False
        except KafkaError as e:
            logger.error(f"‚ùå Kafka –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Å–æ–±—ã—Ç–∏—è {event.event_type}: {e}")
            return False
        except Exception as e:
            logger.error(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Å–æ–±—ã—Ç–∏—è {event.event_type}: {e}")
            return False
    
    def _get_partition_key(self, event: BaseEvent) -> str:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–ª—é—á –¥–ª—è –ø–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∏–ø–∞ —Å–æ–±—ã—Ç–∏—è
        
        Args:
            event: –°–æ–±—ã—Ç–∏–µ
        
        Returns:
            str: –ö–ª—é—á –¥–ª—è –ø–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        # –î–ª—è —Å–æ–±—ã—Ç–∏–π –∑–∞—è–≤–æ–∫ –∏—Å–ø–æ–ª—å–∑—É–µ–º request_id
        if hasattr(event, 'request_id'):
            return str(event.request_id)
        
        # –î–ª—è —Å–æ–±—ã—Ç–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ–º user_id
        if hasattr(event, 'user_id'):
            return str(event.user_id)
        
        # –î–ª—è —Å–æ–±—ã—Ç–∏–π –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ–º contractor_id
        if hasattr(event, 'contractor_id'):
            return str(event.contractor_id)
        
        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ–º event_id
        return event.event_id
    
    def publish_batch(self, events: list) -> Dict[str, int]:
        """
        –ü—É–±–ª–∏–∫–∞—Ü–∏—è –ø–∞–∫–µ—Ç–∞ —Å–æ–±—ã—Ç–∏–π
        
        Args:
            events: –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (topic, event, key)
        
        Returns:
            Dict[str, int]: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏
        """
        results = {"success": 0, "failed": 0}
        
        for topic, event, key in events:
            if self.publish_event(topic, event, key):
                results["success"] += 1
            else:
                results["failed"] += 1
        
        logger.info(f"üìä –ü–∞–∫–µ—Ç–Ω–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {results}")
        return results
    
    def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ producer"""
        if self.producer:
            self.producer.flush()
            self.producer.close()
            logger.info("üîí Kafka Producer –∑–∞–∫—Ä—ã—Ç")

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä producer
kafka_producer = KafkaEventProducer()
